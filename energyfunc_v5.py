'''

@ Author: Wei Wu(ww2384), Hongkai He(hh2581)
A module to test the performance of energy function and boltzman machine
approach on multiple data graph sets for Max-Cut problem

Data Type:
Max-Cut instances generated with rudy

* g05_n.i For each dimension ten unweighted graphs with edge probability 0.5. n=60,80,100.
* pm1s_n.i For each dimension ten weighted graphs with edge weights chosen uniformly from {-1,0,1} and density 0.1. n=80,100
* pm1d_n.i For each dimension ten weighted graphs with edge weights chosen uniformly from {-1,0,1} and density 0.99. n=80,100
* wd_100.i For each density ten graphs with integer edge weights chosen from [-10,10] and density d=0.1,0.5,0.9, n=100.
* pwd_100.i For each density ten graphs with integer edge weights chosen from [0,10] and density d=0.1,0.5,0.9, n=100.

Max-Cut instances from applications in statistical physics (generated by Frauke Liers [Lie04], [LJRR04])

* t2gn_seed For each dimension three two-dimensional toroidal grid graphs with gaussian distributed weights and dimension n times n, n=10,15,20.
* t3gn_seed For each dimension three three-dimensional toroidal grid graphs with gaussian distributed weights and dimension n times n times n, n=5,6,7.
* ising2.5-n_seed For each dimension three one-dimensional Ising chain instances. n=100,150,200,250,300.
* ising3.0-n_seed For each dimension three one-dimensional Ising chain instances. n=100,150,200,250,300.

'''

import numpy as np
import scipy as sp
import random
import math
import os
import time
import csv
from rudy_parser import *
import matplotlib.pyplot as plt

def reweight (weight_matrix):
    num = len(weight_matrix)
    bolz_weight = -weight_matrix * 2
    for i in range(num):
        bolz_weight[i][i] = -sum(bolz_weight[i])/2
    return bolz_weight

def consensus_func(state_m, weight_m):
    state_T = np.array([state_m]).T
    Si_Sj = state_T * state_m
    for i in range(1,len(state_m)):
        for j in range(0,i):
            Si_Sj[i][j] = 0
    energy_m = weight_m * Si_Sj
    C_w = sum(sum(energy_m))
    return C_w

def delta_func(flip_index, state_m, weight_m):
    delta = weight_m[flip_index].dot(state_m)
    if state_m[flip_index] == 0:## S[flip] 0 -> 1
        delta = delta + weight_m[flip_index][flip_index]
    else:
        delta = - delta
    return delta

def prob(T,delta):
    if T < 0.01:
        if delta > 0:
            return 1.0
        else:
            return 0.0
    tmp = -float(delta)/T
    if tmp > 99:
        return 0.0
    elif tmp < -99:
        return 1.0
    else:
        return 1.0/(1+math.exp(tmp))

def annealing(state_m, weight_m, T):
    num = len(state_m)
    cumulativeDelta = 0
    for i in range(num):
        delta = delta_func(i,state_m,weight_m)
        p = prob(T,delta)
        if random.random() <= p:
            state_m[i] = 1 - state_m[i]
            cumulativeDelta += delta
    return [state_m,cumulativeDelta]

def temperature(initial_T, k, k_max):
    return float(initial_T)*(k_max-k)/k_max

def simulation(T, S, W, loop_time):
    # initial parameters
    bolz_weight = reweight(W)
    current_C = consensus_func(S, bolz_weight)
    max_C = current_C
    max_cut = np.array(S)
    C_array = np.zeros([loop_time])

    for k in range(0,loop_time):
        current_T = temperature(T, k, loop_time)
        #print "round " + str(k) + ": T = " + str(current_T)
        #if current_T < 0.05: #T too low, out of range of math.exp() function ####
        #    break;####
        output = annealing(S, bolz_weight, current_T)
        after_state = output[0]
        cum_diff = output[1]
        #current_C = consensus_func(after_state, bolz_weight)
        current_C = current_C + cum_diff
        C_array[k] = current_C####
        max_diff = current_C - max_C
        S = after_state
        # print str(S) + " with distance of " + str(diff) + " from loc opt"
        # print max_cut
        if max_diff > 0:
            max_cut = np.array(after_state)
            max_C = current_C
            # print "record " + str(max_cut) + " with C = " + str(max_C)
            print "Round " + str(k) + "\t: \tT = " + str(current_T) + "\t\t C(w) = " + str(max_C)

    print "\n----------------------------------------------------\n"
    print "Local opt: C(w) = " + str(max_C)
    print "With cut:" + str(max_cut)
    print "\nStop at temperature: " + str(current_T)
    print "Final convergence at: C(w) = " + str(current_C)
    print "With cut:" + str(S)
    return_title = ['max_opt', 'max_cut', 'final_cvg', 'final_cut', 'final_t', 'cvg', 'error_rate', 'start_T']
    return_value = [max_C, max_cut, current_C, S, current_T, max_C == current_C,
                    1 - current_C / max_C, T]
    
    #plt.plot(C_array)
    #plt.show()
    
    return [dict(zip(return_title, return_value)),C_array] 

# write out simulation data
# header encrypted as a default variable
def write_csv(name, dict_data,
              header=['max_opt', 'max_cut', 'final_cvg', 'final_cut', 'final_t', 'cvg', 'error_rate', 'start_T']):
    # fixed path
    path = 'C:/Users/Wuwei/Desktop/Columbia MSOR/Third Semester 2015-9/IEOR E8100/project/res_sets/'
    filename = path + name +'.csv'
    fieldnames = header
    if os.path.isfile(filename):
        with open(filename, 'a') as csvfile:            
            writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\n', fieldnames = fieldnames)
            for row in dict_data:
                writer.writerow(row)
    else:
        with open(filename, 'w') as csvfile:
            writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\n', fieldnames = fieldnames)
            writer.writeheader()
            for row in dict_data:
                writer.writerow(row)

# A very basic and standard test for optimized problem
def basic_case():
    # Test case
    S = [0,1,0,1,1]

    W = [[0, 0, 0, 3, 0],
         [0, 0, 5, 2, 0],
         [0, 5, 0, 0, 4],
         [3, 2, 0, 0, 0],
         [0, 0, 4, 0, 0]]
    T = 220

    W = np.array(W)
    S = np.array(S)
    row = simulation(T, S, W, 100)

    print row

# Try harder test cases
def rudy_case(repeated_times, test_path, name):
    res_list = []
    test_data = read_rudy_data(test_path)
    res = construct_matrices(test_data)
    W = res[1]
    num_edges = res[2]
    # Initial temperature set
    T_Set = [0, 100, num_edges]
    
    for T in T_Set:
        S = res[0]
        print 'Initial random state: ' + str(S)
        d = len(S)
        avg_C = np.zeros([10000])
        
        # let the approximate loop time be d^2 * ln(num_edges)
        # loop_time = int(math.pow(d,2) * math.log(num_edges))
        loop_time = 10000
        for i in range(repeated_times):
            row = simulation(T, S, W, loop_time)
            res_list.append(row[0])
            avg_C += row[1]
            # re-randomize initial state
            S = np.random.randint(2, size=d)
            
        avg_C /= repeated_times
        # print len(avg_C)
        line, = plt.plot(avg_C, label=str(T) + ' F', lw=1) #lw = linewidth ####
        plt.ylabel("C(w)")
        plt.xlabel("Iteration")
        # plt.show()

    ax = plt.gca()
    handles, labels = ax.get_legend_handles_labels()
    ax.legend(handles, labels, loc=4)
    plt.savefig("C:/Users/Wuwei/Desktop/Columbia MSOR/Third Semester 2015-9/IEOR E8100/project/res_sets/pics/"
                + name +"_T_"+str(round(num_edges,2)) +".png", dpi = 480)
    # clear the canvas for the next picture
    plt.clf() 
    
    # write into specific files
    write_csv(name, res_list)

# batch test process for different test data
def batch_test(root_path, repeated_times):
    for filename in os.listdir(root_path):
        t0 = time.clock()
        file_path = root_path + filename
        print 'Run test on : ' + filename
        rudy_case(repeated_times, file_path, filename)
        t1 = time.clock()
        print "\nTime elapsed: " + str(t1-t0) + " secs"

# Test cases
# basic_case()
root_path = 'C:/Users/Wuwei/Desktop/Columbia MSOR/Third Semester 2015-9/IEOR E8100/project/data_sets/test/'
repeated_times = 5

batch_test(root_path, repeated_times)
